{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e21e22",
   "metadata": {},
   "source": [
    "### Phase 3: Transition to Production-Ready Architecture\n",
    "After modularizing the code into `src/` components, the model achieved:\n",
    "- **Recall@1:** 0.8543\n",
    "- **Recall@5:** 0.9790\n",
    "\n",
    "**Observation:** While the model shows exceptional pattern recognition, current metrics reflect performance on the training distribution. Future work involves rigorous cross-validation to ensure generalizability across different learner demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356fb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT ROOT: c:\\Users\\MASTER\\OneDrive\\Desktop\\projects for master\\large projects that prove that you a researcher\\Intelligent Recommendation System for Coding Courses Based on Learner Behavior\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da99ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "\n",
    "from src.feature_engineering import build_sequences\n",
    "from src.model.gru_kt import GRUKT\n",
    "from src.recommender import recommend_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8fd9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7729 rows\n",
      "       timestamp subject_id item_id  is_correct\n",
      "0  1567413540117     u12531   q3605       False\n",
      "1  1567413573276     u12531   q4895       False\n",
      "2  1567413619332     u12531   q5365       False\n",
      "3  1567413640139     u12531   q5577       False\n",
      "4  1567413670061     u12531    q869       False\n"
     ]
    }
   ],
   "source": [
    "processed_csv = r\"C:\\Users\\MASTER\\OneDrive\\Desktop\\projects for master\\large projects that prove that you a researcher\\Intelligent Recommendation System for Coding Courses Based on Learner Behavior\\Data\\data\\processed\\ednet_sequences.csv\"\n",
    "\n",
    "df = pd.read_csv(processed_csv)\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28c5eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 7582\n",
      "Unique items: 3478\n"
     ]
    }
   ],
   "source": [
    "X_items, X_corrs, y, item2idx, idx2item = build_sequences(df, max_len=50)\n",
    "\n",
    "print(f\"Samples: {len(X_items)}\")\n",
    "print(f\"Unique items: {len(item2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292b2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDNetDataset(Dataset):\n",
    "    def __init__(self, X_items, X_corrs, y):\n",
    "        self.X_items = torch.LongTensor(X_items)\n",
    "        self.X_corrs = torch.FloatTensor(X_corrs).clamp(0, 1)\n",
    "        self.y = torch.LongTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_items[idx], self.X_corrs[idx], self.y[idx]\n",
    "\n",
    "dataset = EDNetDataset(X_items, X_corrs, y)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed34a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "n_items = len(item2idx) + 1\n",
    "model = GRUKT(\n",
    "    n_items=n_items,\n",
    "    embed_dim=64,\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e7ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 - Loss: 8.1283\n",
      "Epoch 2/12 - Loss: 7.6662\n",
      "Epoch 3/12 - Loss: 7.1519\n",
      "Epoch 4/12 - Loss: 6.5091\n",
      "Epoch 5/12 - Loss: 5.8002\n",
      "Epoch 6/12 - Loss: 5.1109\n",
      "Epoch 7/12 - Loss: 4.4474\n",
      "Epoch 8/12 - Loss: 3.8477\n",
      "Epoch 9/12 - Loss: 3.3015\n",
      "Epoch 10/12 - Loss: 2.8090\n",
      "Epoch 11/12 - Loss: 2.3947\n",
      "Epoch 12/12 - Loss: 2.0241\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 12\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for items, corrs, labels in loader:\n",
    "        items = items.to(device)\n",
    "        corrs = corrs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(items, corrs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3008a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU + Correct Recall@1: 0.8543\n",
      "GRU + Correct Recall@5: 0.9790\n"
     ]
    }
   ],
   "source": [
    "def recall_at_k(model, dataset, k=5, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    hits, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for items, corrs, y_true in DataLoader(dataset, batch_size=64):\n",
    "            items, corrs, y_true = items.to(device), corrs.to(device), y_true.to(device)\n",
    "            logits = model(items, corrs)\n",
    "            topk = torch.topk(logits, k, dim=1).indices\n",
    "\n",
    "            for i in range(len(y_true)):\n",
    "                hits += int(y_true[i] in topk[i])\n",
    "                total += 1\n",
    "\n",
    "    return hits / total\n",
    "\n",
    "recall1 = recall_at_k(model, dataset, k=1)\n",
    "recall5 = recall_at_k(model, dataset, k=5)\n",
    "\n",
    "print(f\"GRU + Correct Recall@1: {recall1:.4f}\")\n",
    "print(f\"GRU + Correct Recall@5: {recall5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b515d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Item: q743\n",
      "Confidence Score: 15.41%\n"
     ]
    }
   ],
   "source": [
    "example_student = df['subject_id'].iloc[0]\n",
    "student_seq = df[df['subject_id'] == example_student]\n",
    "\n",
    "hist_items = [item2idx[i] for i in student_seq['item_id'].tolist()[:-1]]\n",
    "hist_corrs = student_seq['is_correct'].astype(int).tolist()[:-1]\n",
    "\n",
    "rec_item, confidence = recommend_next(\n",
    "    model,\n",
    "    idx2item,\n",
    "    hist_items,\n",
    "    hist_corrs,\n",
    "    max_len=50,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Recommended Item: {rec_item}\")\n",
    "print(f\"Confidence Score: {confidence:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
